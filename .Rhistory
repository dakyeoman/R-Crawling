}
##클리앙 크롤링
i <- 1
final_data <- NULL
for(i in 1:10){
url <- paste0("https://www.clien.net/service/board/park?&od=T31&category=0&po=0", i= -1)
b <- readLines(url, encoding = "UTF-8") ##or EUC-KR
length(b)
head(b, 30)
tail(b)
#str_extract(b2, "(?<=abc").*(?=ijk)")##abc와 ijk 사이에 있는 텍스트 추출
#str_extract(data, "(?<=abc).*(?=)")##앞에 abc가 있는 것 추출
#str_extract(data, "(?<=).*(?=i)")##뒤에 i가 있는 것 추출
#제목 추출
b2<- b[str_detect(b, "subject_fixed")]
title <- str_extract(b2, "(?<=title=\").*(?=\">)");title
#조회수 추출
b3<- b[str_detect(b, "<span class=\"hit\">")];b3
#b4 <- str_split(b3, "hit\">");b4
##way1
#for(i in 1:10){
hit <- str_extract(b3, "(?<=\">).*(?=</span>)")[-1]
#sapply(b4, function(x){x[1]}) #함수 바로 작성 가능
##way2
#ff<- function(x) {
#   x[2]
# }
# sapply(b4, ff)
# str_sub(sapply(b4, ff), end= -8) #end= -8: 뒤에서 글자 8개를 삭제 *변동
##url 추출
b5 <- b[which(str_detect(b, "subject_fixed")) -2]
#which: TRUE값이 있는 index만 추출
#-2 : 소스코드에서 제목 두 줄 앞
b6 <- str_sub(str_extract(b5, "(?<=href=\").*(?=data-role)"), end = -4)
url <- paste0("https://www.clien.net", b6)
data <- cbind(title, hit, url)
final_data <- rbind(final_data, data)
cat("\n", i)
}
length(title)
length(hit)
length(url)
for(i in 1:10){
hit <- str_extract(b3, "(?<=\">).*(?=</span>)")[-1]
#sapply(b4, function(x){x[1]}) #함수 바로 작성 가능
##way2
#ff<- function(x) {
#   x[2]
# }
# sapply(b4, ff)
# str_sub(sapply(b4, ff), end= -8) #end= -8: 뒤에서 글자 8개를 삭제 *변동
##url 추출
b5 <- b[which(str_detect(b, "subject_fixed")) -2]
#which: TRUE값이 있는 index만 추출
#-2 : 소스코드에서 제목 두 줄 앞
b6 <- str_sub(str_extract(b5, "(?<=href=\").*(?=data-role)"), end = -4)
url <- paste0("https://www.clien.net", b6)
data <- cbind(title, hit, url)
final_data <- rbind(final_data, data)
cat("\n", i)
}
length(title)
library(stringr)
##클리앙 크롤링
i <- 1
final_data <- NULL
for(i in 1:10){
b <- readLines(url, encoding = "UTF-8") ##or EUC-KR
length(b)
head(b, 30)
tail(b)
#제목 추출
b2<- b[str_detect(b, "subject_fixed")]
title <- str_extract(b2, "(?<=title=\").*(?=\">)");title
#조회수 추출
b3<- b[str_detect(b, "<span class=\"hit\">")];b3
for(i in 1:10){
hit <- str_extract(b3, "(?<=\">).*(?=</span>)")[-1]
#sapply(b4, function(x){x[1]}) #함수 바로 작성 가능
##way2
#ff<- function(x) {
#   x[2]
# }
# sapply(b4, ff)
# str_sub(sapply(b4, ff), end= -8) #end= -8: 뒤에서 글자 8개를 삭제 *변동
##url 추출
b5 <- b[which(str_detect(b, "subject_fixed")) -2]
#which: TRUE값이 있는 index만 추출
#-2 : 소스코드에서 제목 두 줄 앞
b6 <- str_sub(str_extract(b5, "(?<=href=\").*(?=data-role)"), end = -4)
url <- paste0("https://www.clien.net", b6)
data <- cbind(title, hit, url)
final_data <- rbind(final_data, data)
cat("\n", i)
}
length(title)
length(hit)
length(url)
#b4 <- str_split(b3, "hit\">");b4
##way1
hit <- str_extract(b3, "(?<=\">).*(?=</span>)")[-1]
##url 추출
b5 <- b[which(str_detect(b, "subject_fixed")) -2]
b6 <- str_sub(str_extract(b5, "(?<=href=\").*(?=data-role)"), end = -4)
url <- paste0("https://www.clien.net", b6)
data <- cbind(title, hit, url)
final_data <- rbind(final_data, data)
cat("\n", i)
for(i in 1:10){
url <- paste0("https://www.clien.net/service/board/park?&od=T31&category=0&po=0", i= -1)
b <- readLines(url, encoding = "UTF-8") ##or EUC-KR
length(b)
head(b, 30)
tail(b)
#str_extract(b2, "(?<=abc").*(?=ijk)")##abc와 ijk 사이에 있는 텍스트 추출
#str_extract(data, "(?<=abc).*(?=)")##앞에 abc가 있는 것 추출
#str_extract(data, "(?<=).*(?=i)")##뒤에 i가 있는 것 추출
#제목 추출
b2<- b[str_detect(b, "subject_fixed")]
title <- str_extract(b2, "(?<=title=\").*(?=\">)");title
#조회수 추출
b3<- b[str_detect(b, "<span class=\"hit\">")];b3
#b4 <- str_split(b3, "hit\">");b4
##way1
hit <- str_extract(b3, "(?<=\">).*(?=</span>)")[-1]
#sapply(b4, function(x){x[1]}) #함수 바로 작성 가능
##way2
#ff<- function(x) {
#   x[2]
# }
# sapply(b4, ff)
# str_sub(sapply(b4, ff), end= -8) #end= -8: 뒤에서 글자 8개를 삭제 *변동
##url 추출
b5 <- b[which(str_detect(b, "subject_fixed")) -2]
#which: TRUE값이 있는 index만 추출
#-2 : 소스코드에서 제목 두 줄 앞
b6 <- str_sub(str_extract(b5, "(?<=href=\").*(?=data-role)"), end = -4)
url <- paste0("https://www.clien.net", b6)
data <- cbind(title, hit, url)
final_data <- rbind(final_data, data)
cat("\n", i)
}
length(title)
length(hit)
cat("\n", i)}
}
cat("\n", i)}
for(i in 1:10){
url <- paste0("https://www.clien.net/service/board/park?&od=T31&category=0&po=0", i= -1)
b <- readLines(url, encoding = "UTF-8") ##or EUC-KR
length(b)
head(b, 30)
tail(b)
#str_extract(b2, "(?<=abc").*(?=ijk)")##abc와 ijk 사이에 있는 텍스트 추출
#str_extract(data, "(?<=abc).*(?=)")##앞에 abc가 있는 것 추출
#str_extract(data, "(?<=).*(?=i)")##뒤에 i가 있는 것 추출
#제목 추출
b2<- b[str_detect(b, "subject_fixed")]
title <- str_extract(b2, "(?<=title=\").*(?=\">)");title
#조회수 추출
b3<- b[str_detect(b, "<span class=\"hit\">")];b3
#b4 <- str_split(b3, "hit\">");b4
##way1
hit <- str_extract(b3, "(?<=\">).*(?=</span>)")[-1]
#sapply(b4, function(x){x[1]}) #함수 바로 작성 가능
##way2
#ff<- function(x) {
#   x[2]
# }
# sapply(b4, ff)
# str_sub(sapply(b4, ff), end= -8) #end= -8: 뒤에서 글자 8개를 삭제 *변동
##url 추출
b5 <- b[which(str_detect(b, "subject_fixed")) -2]
#which: TRUE값이 있는 index만 추출
#-2 : 소스코드에서 제목 두 줄 앞
b6 <- str_sub(str_extract(b5, "(?<=href=\").*(?=data-role)"), end = -4)
url <- paste0("https://www.clien.net", b6)
data <- cbind(title, hit, url)
final_data <- rbind(final_data, data)
cat("\n", i)
}
for(i in 1:10){
url <- paste0("https://www.clien.net/service/board/park?&od=T31&category=0&po=0", i= -1)
b <- readLines(url, encoding = "UTF-8") ##or EUC-KR
length(b)
head(b, 30)
tail(b)
#str_extract(b2, "(?<=abc").*(?=ijk)")##abc와 ijk 사이에 있는 텍스트 추출
#str_extract(data, "(?<=abc).*(?=)")##앞에 abc가 있는 것 추출
#str_extract(data, "(?<=).*(?=i)")##뒤에 i가 있는 것 추출
#제목 추출
b2<- b[str_detect(b, "subject_fixed")]
title <- str_extract(b2, "(?<=title=\").*(?=\">)");title
#조회수 추출
b3<- b[str_detect(b, "<span class=\"hit\">")];b3
#b4 <- str_split(b3, "hit\">");b4
##way1
hit <- str_extract(b3, "(?<=\">).*(?=</span>)")[-1]
#sapply(b4, function(x){x[1]}) #함수 바로 작성 가능
##way2
#ff<- function(x) {
#   x[2]
# }
# sapply(b4, ff)
# str_sub(sapply(b4, ff), end= -8) #end= -8: 뒤에서 글자 8개를 삭제 *변동
##url 추출
b5 <- b[which(str_detect(b, "subject_fixed")) -2]
#which: TRUE값이 있는 index만 추출
#-2 : 소스코드에서 제목 두 줄 앞
b6 <- str_sub(str_extract(b5, "(?<=href=\").*(?=data-role)"), end = -4)
url <- paste0("https://www.clien.net", b6)
data <- cbind(title, hit, url)
final_data <- rbind(final_data, data)
cat("\n", i)
}
length(title)
length(hit)
length(url)
##클리앙 크롤링
i <- 1
final_data <- NULL
for(i in 1:10){
url <- paste0("https://www.clien.net/service/board/park?&od=T31&category=0&po=0", i= -1)
b <- readLines(url, encoding = "UTF-8") ##or EUC-KR
length(b)
head(b, 30)
tail(b)
#str_extract(b2, "(?<=abc").*(?=ijk)")##abc와 ijk 사이에 있는 텍스트 추출
#str_extract(data, "(?<=abc).*(?=)")##앞에 abc가 있는 것 추출
#str_extract(data, "(?<=).*(?=i)")##뒤에 i가 있는 것 추출
#제목 추출
b2<- b[str_detect(b, "subject_fixed")]
title <- str_extract(b2, "(?<=title=\").*(?=\">)");title
#조회수 추출
b3<- b[str_detect(b, "<span class=\"hit\">")];b3
#b4 <- str_split(b3, "hit\">");b4
##way1
hit <- str_extract(b3, "(?<=\">).*(?=</span>)")[-1]
#sapply(b4, function(x){x[1]}) #함수 바로 작성 가능
##way2
#ff<- function(x) {
#   x[2]
# }
# sapply(b4, ff)
# str_sub(sapply(b4, ff), end= -8) #end= -8: 뒤에서 글자 8개를 삭제 *변동
##url 추출
b5 <- b[which(str_detect(b, "subject_fixed")) -2]
#which: TRUE값이 있는 index만 추출
#-2 : 소스코드에서 제목 두 줄 앞
b6 <- str_sub(str_extract(b5, "(?<=href=\").*(?=data-role)"), end = -4)
url <- paste0("https://www.clien.net", b6)
data <- cbind(title, hit, url)
final_data <- rbind(final_data, data)
cat("\n", i)
}
length(title)
length(hit)
length(url)
for(i in 0:9){
url <- paste0("https://www.clien.net/service/board/park?&od=T31&category=0&po=0", i)
b <- readLines(url, encoding = "UTF-8") ##or EUC-KR
length(b)
head(b, 30)
tail(b)
#str_extract(b2, "(?<=abc").*(?=ijk)")##abc와 ijk 사이에 있는 텍스트 추출
#str_extract(data, "(?<=abc).*(?=)")##앞에 abc가 있는 것 추출
#str_extract(data, "(?<=).*(?=i)")##뒤에 i가 있는 것 추출
#제목 추출
b2<- b[str_detect(b, "subject_fixed")]
title <- str_extract(b2, "(?<=title=\").*(?=\">)");title
#조회수 추출
b3<- b[str_detect(b, "<span class=\"hit\">")];b3
#b4 <- str_split(b3, "hit\">");b4
##way1
hit <- str_extract(b3, "(?<=\">).*(?=</span>)")[-1]
#sapply(b4, function(x){x[1]}) #함수 바로 작성 가능
##way2
#ff<- function(x) {
#   x[2]
# }
# sapply(b4, ff)
# str_sub(sapply(b4, ff), end= -8) #end= -8: 뒤에서 글자 8개를 삭제 *변동
##url 추출
b5 <- b[which(str_detect(b, "subject_fixed")) -2]
#which: TRUE값이 있는 index만 추출
#-2 : 소스코드에서 제목 두 줄 앞
b6 <- str_sub(str_extract(b5, "(?<=href=\").*(?=data-role)"), end = -4)
url <- paste0("https://www.clien.net", b6)
data <- cbind(title, hit, url)
final_data <- rbind(final_data, data)
cat("\n", i)
}
length(title)
length(hit)
length(url)
dim(final_data)
head(final_data)
tail(final_data)
write.csv(final_data, "base_data.csv", row.names=F)
write.csv(final_data, "base_data.csv", row.names=F)
setwd("/Users/adrua/Desktop/Crawling_R")
write.csv(final_data, "base_data.csv", row.names=F)
setwd("/Users/adrua/Desktop/R-Crawling_new/R-Crqwling")
setwd("/Users/adrua/Desktop/R-Crawling_new/R-Crawling")
write.csv(final_data, "base_data.csv", row.names=F)
setwd(paste0("/Users/adrua/Desktop/R-Crawling_new/R-Crawling",folder_list[i]))
setwd(paste0("/Users/adrua/Desktop/R-Crawling_new/R-Crawling/",folder_list[i]))
folder_list[i]
setwd(paste0("/Users/adrua/Desktop/R-Crawling_new/R-Crawling/",folder_list[i]))
setwd("/Users/adrua/Desktop/R-Crawling_new/R-Crawling/")
setwd("/Users/adrua/Desktop/R-Crawling_new/R-Crawling/")
getwd()
write.csv(m3, "m3.csv", row.names=F) #row.names=F: 행 이름 저장X
m4 <- read.csv("m3.csv")
m4
setwd("/Users/adrua/Desktop/R-Crawling_new/R-Crawling/")
file_list <- list.files()
setwd("/Users/adrua/Desktop/R-Crawling_new/R-Crawling/")
#roof2
setwd("/Users/adrua/Desktop/R-Crawling_new/R-Crawling/")
setwd(paste0("/Users/adrua/Desktop/R-Crawling_new/R-Crawling/",folder_list[i]))
library(stringr)
##클리앙 크롤링
i <- 1
final_data <- NULL
for(i in 0:9){
url <- paste0("https://www.clien.net/service/board/park?&od=T31&category=0&po=0", i)
b <- readLines(url, encoding = "UTF-8") ##or EUC-KR
length(b)
head(b, 30)
tail(b)
#str_extract(b2, "(?<=abc").*(?=ijk)")##abc와 ijk 사이에 있는 텍스트 추출
#str_extract(data, "(?<=abc).*(?=)")##앞에 abc가 있는 것 추출
#str_extract(data, "(?<=).*(?=i)")##뒤에 i가 있는 것 추출
#제목 추출
b2<- b[str_detect(b, "subject_fixed")]
title <- str_extract(b2, "(?<=title=\").*(?=\">)");title
#조회수 추출
b3<- b[str_detect(b, "<span class=\"hit\">")];b3
#b4 <- str_split(b3, "hit\">");b4
##way1
hit <- str_extract(b3, "(?<=\">).*(?=</span>)")[-1]
#sapply(b4, function(x){x[1]}) #함수 바로 작성 가능
##way2
#ff<- function(x) {
#   x[2]
# }
# sapply(b4, ff)
# str_sub(sapply(b4, ff), end= -8) #end= -8: 뒤에서 글자 8개를 삭제 *변동
##url 추출
b5 <- b[which(str_detect(b, "subject_fixed")) -2]
#which: TRUE값이 있는 index만 추출
#-2 : 소스코드에서 제목 두 줄 앞
b6 <- str_sub(str_extract(b5, "(?<=href=\").*(?=data-role)"), end = -4)
url <- paste0("https://www.clien.net", b6)
data <- cbind(title, hit, url)
final_data <- rbind(final_data, data)
cat("\n", i)
}
length(title)
dim(final_data)
head(final_data)
tail(final_data)
setwd("/Users/adrua/Desktop/R-Crawling_new/R-Crawling")
write.csv(final_data, "base_data.csv", row.names=F)
setwd("/Users/adrua/Desktop/R-Crawling_new/R-Crawling")
read.csv()
read.cssv("base_data.vsv")
head(data)
data <- read.csv("base_data.vsv")
head(data)
save(data, file+"base_data.RData")
save(data, file="base_data.RData")
load("base_data.RData")
data[,3]
url_list <- data[,3]
url_list[1]
library(stringr)
##클리앙 크롤링
i <- 1
final_data <- NULL
for(i in 0:9){
url <- paste0("https://www.clien.net/service/board/park?&od=T31&category=0&po=0", i)
b <- readLines(url, encoding = "UTF-8") ##or EUC-KR
length(b)
head(b, 30)
tail(b)
#str_extract(b2, "(?<=abc").*(?=ijk)")##abc와 ijk 사이에 있는 텍스트 추출
#str_extract(data, "(?<=abc).*(?=)")##앞에 abc가 있는 것 추출
#str_extract(data, "(?<=).*(?=i)")##뒤에 i가 있는 것 추출
#제목 추출
b2<- b[str_detect(b, "subject_fixed")]
title <- str_extract(b2, "(?<=title=\").*(?=\">)");title
#조회수 추출
b3<- b[str_detect(b, "<span class=\"hit\">")];b3
#b4 <- str_split(b3, "hit\">");b4
##way1
hit <- str_extract(b3, "(?<=\">).*(?=</span>)")[-1]
#sapply(b4, function(x){x[1]}) #함수 바로 작성 가능
##way2
#ff<- function(x) {
#   x[2]
# }
# sapply(b4, ff)
# str_sub(sapply(b4, ff), end= -8) #end= -8: 뒤에서 글자 8개를 삭제 *변동
##url 추출
b5 <- b[which(str_detect(b, "subject_fixed")) -2]
#which: TRUE값이 있는 index만 추출
#-2 : 소스코드에서 제목 두 줄 앞
b6 <- str_sub(str_extract(b5, "(?<=href=\").*(?=data-role)"), end = -4)
url <- paste0("https://www.clien.net", b6)
data <- cbind(title, hit, url)
final_data <- rbind(final_data, data)
cat("\n", i)
}
length(title)
dim(final_data)
head(final_data)
tail(final_data)
setwd("/Users/adrua/Desktop/R-Crawling_new/R-Crawling")
write.csv(final_data, "base_d ata.csv", row.names=F)
#csv로 저장하고 불러오기
setwd("/Users/adrua/Desktop/R-Crawling_new/R-Crawling")
data <- read.csv("base_data.vsv")
head(data)
url_list <- data[,3]
url_list[10]
redaLines(url_list[1], encoding = "UTF-8")
readLines(url_list[1], encoding = "UTF-8")
b <- readLines(url_list[1], encoding = "UTF-8")
b
#url_list[10] , 소스코드에서 post_content / post_ccls에 원문이 있음
b <- readLines(as.character(url_list[1], encoding = "UTF-8"))
b
#url_list[10] , 소스코드에서 post_content / post_ccls에 원문이 있음
b <- readLines(as.character(url_list[1]), encoding = "UTF-8")
b
#url_list[10] , 소스코드에서 post_content / post_ccls에 원문이 있음
length(url_llist)
#url_list[10] , 소스코드에서 post_content / post_ccls에 원문이 있음
length(url_list)
#csv로 저장하고 불러오기
setwd("/Users/adrua/Desktop/R-Crawling_new/R-Crawling")
data <- read.csv("base_data.vsv")
head(data)
url_list <- data[,3]
#url_list[10] , 소스코드에서 post_content / post_ccls에 원문이 있음
length(url_list)
url_list <- data[,3] ;url_list
library(stringr)
##클리앙 크롤링
i <- 1
final_data <- NULL
for(i in 0:9){
url <- paste0("https://www.clien.net/service/board/park?&od=T31&category=0&po=0", i)
b <- readLines(url, encoding = "UTF-8") ##or EUC-KR
length(b)
head(b, 30)
tail(b)
#str_extract(b2, "(?<=abc").*(?=ijk)")##abc와 ijk 사이에 있는 텍스트 추출
#str_extract(data, "(?<=abc).*(?=)")##앞에 abc가 있는 것 추출
#str_extract(data, "(?<=).*(?=i)")##뒤에 i가 있는 것 추출
#제목 추출
b2<- b[str_detect(b, "subject_fixed")]
title <- str_extract(b2, "(?<=title=\").*(?=\">)");title
#조회수 추출
b3<- b[str_detect(b, "<span class=\"hit\">")];b3
#b4 <- str_split(b3, "hit\">");b4
##way1
hit <- str_extract(b3, "(?<=\">).*(?=</span>)")[-1]
#sapply(b4, function(x){x[1]}) #함수 바로 작성 가능
##way2
#ff<- function(x) {
#   x[2]
# }
# sapply(b4, ff)
# str_sub(sapply(b4, ff), end= -8) #end= -8: 뒤에서 글자 8개를 삭제 *변동
##url 추출
b5 <- b[which(str_detect(b, "subject_fixed")) -2]
#which: TRUE값이 있는 index만 추출
#-2 : 소스코드에서 제목 두 줄 앞
b6 <- str_sub(str_extract(b5, "(?<=href=\").*(?=data-role)"), end = -4)
url <- paste0("https://www.clien.net", b6)
data <- cbind(title, hit, url)
final_data <- rbind(final_data, data)
cat("\n", i)
}
length(title)
dim(final_data)
head(final_data)
dim(final_data)
setwd("/Users/adrua/Desktop/R-Crawling_new/R-Crawling")
write.csv(final_data, "base_d ata.csv", row.names=F)
write.csv(final_data, "base_data.csv", row.names=F)
#csv로 저장하고 불러오기
setwd("/Users/adrua/Desktop/R-Crawling_new/R-Crawling")
data <- read.csv("base_data.vsv")
head(data)
url_list <- data[,3] ;url_list
#url_list[10] , 소스코드에서 post_content / post_ccls에 원문이 있음
length(url_list)
b <- readLines(as.character(url_list[1]), encoding = "UTF-8")
b
#csv로 저장하고 불러오기
setwd("/Users/adrua/Desktop/R-Crawling_new/R-Crawling")
data <- read.csv("base_data.vsv")
head(data)
url_list <- data[,3] ;url_list
#url_list[10] , 소스코드에서 post_content / post_ccls에 원문이 있음
length(url_list)
b <- readLines(as.character(url_list[1]), encoding = "UTF-8")
b
