final_data<- rbind(final_data, data)
cat("\n", i)
}
dim(final_data)
head(final_data)#엥 이상하다 27분 02초
##클리앙 크롤링
i <- 1
final_data <- NULL
for(i in 1:10){
b <- readLines(url, encoding = "UTF-8") ##or EUC-KR
length(b)
head(b, 30)
tail(b)
#제목 추출
b2<- b[str_detect(b, "subject_fixed")]
title <- str_extract(b2, "(?<=title=\").*(?=\">)")
#조회수 추출
b3<- b[str_detect(b, "<span class=\"hit\">")];b3
for(i in 1:10){
hit <- str_extract(b3, "(?<=\">).*(?=</span>)")[-1]
#sapply(b4, function(x){x[1]}) #함수 바로 작성 가능
##way2
#ff<- function(x) {
#   x[2]
# }
# sapply(b4, ff)
# str_sub(sapply(b4, ff), end= -8) #end= -8: 뒤에서 글자 8개를 삭제 *변동
##url 추출
b5 <- b[which(str_detect(b, "subject_fixed")) -2]
#which: TRUE값이 있는 index만 추출
#-2 : 소스코드에서 제목 두 줄 앞
b6 <- str_sub(str_extract(b5, "(?<=href=\").*(?=data-role)"), end = -4)
url <- paste0("https://www.clien.net", b6)
data <- cbind(title, hit, url)
final_data<- rbind(final_data, data)
cat("\n", i)
}
dim(final_data)
head(final_data)#엥 이상하다 27분 02초
for(i in 1:10){
hit <- str_extract(b3, "(?<=\">).*(?=</span>)")[-1]
#sapply(b4, function(x){x[1]}) #함수 바로 작성 가능
##way2
#ff<- function(x) {
#   x[2]
# }
# sapply(b4, ff)
# str_sub(sapply(b4, ff), end= -8) #end= -8: 뒤에서 글자 8개를 삭제 *변동
##url 추출
b5 <- b[which(str_detect(b, "subject_fixed")) -2]
#which: TRUE값이 있는 index만 추출
#-2 : 소스코드에서 제목 두 줄 앞
b6 <- str_sub(str_extract(b5, "(?<=href=\").*(?=data-role)"), end = -4)
url <- paste0("https://www.clien.net", b6)
data <- cbind(title, hit, url)
final_data<- rbind(final_data, data)
cat("\n", i)
}
for(i in 1:10){
url <- paste0("https://www.clien.net/service/board/park?&od=T31&category=0&po=0", i= -1)
b <- readLines(url, encoding = "UTF-8") ##or EUC-KR
length(b)
head(b, 30)
tail(b)
#str_extract(b2, "(?<=abc").*(?=ijk)")##abc와 ijk 사이에 있는 텍스트 추출
#str_extract(data, "(?<=abc).*(?=)")##앞에 abc가 있는 것 추출
#str_extract(data, "(?<=).*(?=i)")##뒤에 i가 있는 것 추출
#제목 추출
b2<- b[str_detect(b, "subject_fixed")]
title <- str_extract(b2, "(?<=title=\").*(?=\">)")
#조회수 추출
b3<- b[str_detect(b, "<span class=\"hit\">")];b3
#b4 <- str_split(b3, "hit\">");b4
##way1
for(i in 1:10){
hit <- str_extract(b3, "(?<=\">).*(?=</span>)")[-1]
#sapply(b4, function(x){x[1]}) #함수 바로 작성 가능
##way2
#ff<- function(x) {
#   x[2]
# }
# sapply(b4, ff)
# str_sub(sapply(b4, ff), end= -8) #end= -8: 뒤에서 글자 8개를 삭제 *변동
##url 추출
b5 <- b[which(str_detect(b, "subject_fixed")) -2]
#which: TRUE값이 있는 index만 추출
#-2 : 소스코드에서 제목 두 줄 앞
b6 <- str_sub(str_extract(b5, "(?<=href=\").*(?=data-role)"), end = -4)
url <- paste0("https://www.clien.net", b6)
data <- cbind(title, hit, url)
final_data<- rbind(final_data, data)
cat("\n", i)
}
}
for(i in 1:10){
hit <- str_extract(b3, "(?<=\">).*(?=</span>)")[-1]
}
##클리앙 크롤링
i <- 1
final_data <- NULL
for(i in 1:10){
b <- readLines(url, encoding = "UTF-8") ##or EUC-KR
length(b)
head(b, 30)
tail(b)
#제목 추출
b2<- b[str_detect(b, "subject_fixed")]
title <- str_extract(b2, "(?<=title=\").*(?=\">)")
#조회수 추출
b3<- b[str_detect(b, "<span class=\"hit\">")];b3
for(i in 1:10){
hit <- str_extract(b3, "(?<=\">).*(?=</span>)")[-1]
}
##클리앙 크롤링
i <- 1
final_data <- NULL
for(i in 1:10){
url <- paste0("https://www.clien.net/service/board/park?&od=T31&category=0&po=0", i= -1)
b <- readLines(url, encoding = "UTF-8") ##or EUC-KR
length(b)
head(b, 30)
tail(b)
}
##클리앙 크롤링
i <- 1
library(stringr)
dc_data <- NULL
for(i in 1:10){
url <- paste0("https://gall.dcinside.com/board/lists/?id=superidea&page=", i)
b <- readLines(url, encoding = "UTF-8")
#제목/url
index <- which(str_detect(b, "gall_tit ub-word"))[-1]
b2 <- b[index+1]
title <- str_trim(str_extract(b2, ("(?<=</strong>).*(?=</a>)")))
con_url <- str_sub(str_extract(b2, ("(?<=a href=).*(?=em class)")), 3, end = -17)
con_url2 <- paste0("https://gall.dcinside.com/", con_url)
#조회수
hit_index <- which(str_detect(b, "gall_count"))[-1]
hit <- as.numeric(str_sub(str_extract(b[hit_index], ("(?<=gall_count).*(?=</td>)")), 3))
hit
#추천수
rec_index <- which(str_detect(b, "gall_recommend"))[-1]
rec <- as.numeric(str_extract(b[rec_index], ("(?<=gall_recommend\">).*(?=</td>)")))
data <- cbind(title, con_url2, hit, rec) #->one matrix
dc_data <- rbind(dc_data, data)
cat("\n", i)
}
head(dc_data)
dim(dc_data)
setwd("/Users/adrua/Desktop/R-Crawling_new/R-Crawling/")
write.csv(dc_data, "dc_data.csv", row.names = F)
data <- read.csv("dc_data.csv")
head(data)
dim(data)
url <- as.character(data$con_url2);url
i <- 1
contents <- c()
for(i in 1:length(url)){
b <- readLines(url[i], encoding = "UTF-8")
Sys.sleep(runif(1)*2)
b2 <- b[which(str_detect(b, "gallview_contents")):which(str_detect(b, " 본문 우측 광고 "))]
b3 <- paste(b2, collapse = " ");b3
b4 <- gsub("<.*?>", "", b3);b4
b5 <- gsub("\t|&nbsp;", "", b4) ; b5
con <- str_trim(b5);con
contents <- c(contents, con)
cat("\n", i)
}
dim(data)
data2 <- cbind(data, contents)
write.csv(data2, "dc.csv", row.names = F)
#csv로 저장하고 불러오기
setwd("/Users/adrua/Desktop/R-Crawling_new/R-Crawling")
data <- read.csv("base_data.csv")
head(data)
##R파일로 저장하고 불러오기(리스트)
#save(data, file="base_data.RData")
#load("base_data.RData")
library(stringr)
url_list <- data[,3]
length(url_list)
content <- c()
for(i in 1:length(url_list)){
if(class(try(b <- readLines(as.character(url_list[i]), encoding = "UTF-8"))) == "try-error"){
b6 <- "."
content <- c(content, b6)
}else{
b2 <- b[which(str_detect(b, "post_content")):which(str_detect(b, "post_ccls"))]
b3 <- paste(b2, collapse = "")
b4 <- gsub("<.*?>", "", b3)
b5 <- gsub("\t|&nbsp", "", b4)
b6 <- str_trim(b5)
content <- c(content, b6)
cat("\n", i)
}
}
head(content)
final_data <- cbind(data, content)
write.csv(final_data, "final_data.csv", row.names = F)
dim(content)
url_list <- data[,3]
head(url_list)
#url_list[10] , 소스코드에서 post_content / post_ccls사이에 원문이 있음
length(url_list) #300 출력됨
content <- c()
if(class(try(b <- readLines(as.character(url_list[i]), encoding = "UTF-8"))) =="try-error"){
b6 <- ""
content <- c(content, b6)
#next;
}else{
b2 <- b[which(str_detect(b, "post_content")):which(str_detect(b, "post_ccls"))]
#출력된 21개 벡터 하나로 합치기 paste(데이터, collapse = 구분자)
b3 <- paste(b2, collapse = "")
#태그 삭제
b4 <- gsub("<.*?>", "", b3) #<.*?>: <>사이 모든 것 삭제
b5 <- gsub("\t|&nbsp;", "", b4)
#앞 뒤 공백 삭제
b6 <- str_trim(b5)
content <- c(content, b6)
cat("\n", i)
}
}
head(content)
final_data <- cbind(data, content)
colnames(final_data)
#주석 포함된 코드 (but 에러남)
url_list <- data[,3]
head(url_list)
length(url_list) #300 출력됨
content <- c()
if(class(try(b <- readLines(as.character(url_list[i]), encoding = "UTF-8"))) =="try-error"){
b6 <- ""
content <- c(content, b6)
#next;
}else{
b2 <- b[which(str_detect(b, "post_content")):which(str_detect(b, "post_ccls"))]
#출력된 21개 벡터 하나로 합치기 paste(데이터, collapse = 구분자)
b3 <- paste(b2, collapse = "")
#태그 삭제
b4 <- gsub("<.*?>", "", b3) #<.*?>: <>사이 모든 것 삭제
b5 <- gsub("\t|&nbsp;", "", b4)
#앞 뒤 공백 삭제
b6 <- str_trim(b5)
content <- c(content, b6)
cat("\n", i)
}
}
head(content)
final_data <- cbind(data, content)
colnames(final_data)
url <- paste0("https://gall.dcinside.com/board/lists/?id=superidea&page=", i)
b <- readLines(url, encoding = "UTF-8")
#제목/url
index <- which(str_detect(b, "gall_tit ub-word"))[-1]
b2 <- b[index+1]
for(i in 1:10){
url <- paste0("https://gall.dcinside.com/board/lists/?id=superidea&page=", i)
b <- readLines(url, encoding = "UTF-8")
#제목/url
index <- which(str_detect(b, "gall_tit ub-word"))[-1]
b2 <- b[index+1]
title <- str_trim(str_extract(b2, ("(?<=</strong>).*(?=</a>)")))
con_url <- str_sub(str_extract(b2, ("(?<=a href=).*(?=em class)")), 3, end = -17)
con_url2 <- paste0("https://gall.dcinside.com/", con_url)
#조회수
hit_index <- which(str_detect(b, "gall_count"))[-1]
hit <- as.numeric(str_sub(str_extract(b[hit_index], ("(?<=gall_count).*(?=</td>)")), 3))
hit
#추천수
rec_index <- which(str_detect(b, "gall_recommend"))[-1]
rec <- as.numeric(str_extract(b[rec_index], ("(?<=gall_recommend\">).*(?=</td>)")))
data <- cbind(title, con_url2, hit, rec) #->one matrix
dc_data <- rbind(dc_data, data)
cat("\n", i)
}
head(dc_data)
dim(dc_data)
setwd("/Users/adrua/Desktop/R-Crawling_new/R-Crawling/")
write.csv(dc_data, "dc_data.csv", row.names = F)
data <- read.csv("dc_data.csv")
data <- read.csv("dc_data.csv")
head(data)
dim(data)
data <- read.csv("dc_data.csv")
head(data)
library(stringr)
dc_data <- NULL
for(i in 1:10){
url <- paste0("https://gall.dcinside.com/board/lists/?id=superidea&page=", i)
b <- readLines(url, encoding = "UTF-8")
#제목/url
index <- which(str_detect(b, "gall_tit ub-word"))[-1]
b2 <- b[index+1]
title <- str_trim(str_extract(b2, ("(?<=</strong>).*(?=</a>)")))
con_url <- str_sub(str_extract(b2, ("(?<=a href=).*(?=em class)")), 3, end = -17)
con_url2 <- paste0("https://gall.dcinside.com/", con_url)
#조회수
hit_index <- which(str_detect(b, "gall_count"))[-1]
hit <- as.numeric(str_sub(str_extract(b[hit_index], ("(?<=gall_count).*(?=</td>)")), 3))
hit
#추천수
rec_index <- which(str_detect(b, "gall_recommend"))[-1]
rec <- as.numeric(str_extract(b[rec_index], ("(?<=gall_recommend\">).*(?=</td>)")))
data <- cbind(title, con_url2, hit, rec) #->one matrix
dc_data <- rbind(dc_data, data)
cat("\n", i)
}
head(dc_data)
Sys.sleep(runif(1)*2)
#제목/url
index <- which(str_detect(b, "gall_tit ub-word"))[-1]
dc_data <- NULL
for(i in 1:10){
url <- paste0("https://gall.dcinside.com/board/lists/?id=superidea&page=", i)
b <- readLines(url, encoding = "UTF-8")
Sys.sleep(runif(1)*2)
#제목/url
index <- which(str_detect(b, "gall_tit ub-word"))[-1]
b2 <- b[index+1]
title <- str_trim(str_extract(b2, ("(?<=</strong>).*(?=</a>)")))
con_url <- str_sub(str_extract(b2, ("(?<=a href=).*(?=em class)")), 3, end = -17)
con_url2 <- paste0("https://gall.dcinside.com/", con_url)
#조회수
hit_index <- which(str_detect(b, "gall_count"))[-1]
hit <- as.numeric(str_sub(str_extract(b[hit_index], ("(?<=gall_count).*(?=</td>)")), 3))
hit
#추천수
rec_index <- which(str_detect(b, "gall_recommend"))[-1]
rec <- as.numeric(str_extract(b[rec_index], ("(?<=gall_recommend\">).*(?=</td>)")))
data <- cbind(title, con_url2, hit, rec) #->one matrix
dc_data <- rbind(dc_data, data)
cat("\n", i)
}
head(dc_data)
Sys.sleep(runif(1)*2)
for(i in 1:10){
url <- paste0("https://gall.dcinside.com/board/lists/?id=superidea&page=", i)
Sys.sleep(runif(1)*2)
b <- readLines(url, encoding = "UTF-8")
#제목/url
index <- which(str_detect(b, "gall_tit ub-word"))[-1]
b2 <- b[index+1]
title <- str_trim(str_extract(b2, ("(?<=</strong>).*(?=</a>)")))
con_url <- str_sub(str_extract(b2, ("(?<=a href=).*(?=em class)")), 3, end = -17)
con_url2 <- paste0("https://gall.dcinside.com/", con_url)
#조회수
hit_index <- which(str_detect(b, "gall_count"))[-1]
hit <- as.numeric(str_sub(str_extract(b[hit_index], ("(?<=gall_count).*(?=</td>)")), 3))
hit
#추천수
rec_index <- which(str_detect(b, "gall_recommend"))[-1]
rec <- as.numeric(str_extract(b[rec_index], ("(?<=gall_recommend\">).*(?=</td>)")))
data <- cbind(title, con_url2, hit, rec) #->one matrix
dc_data <- rbind(dc_data, data)
cat("\n", i)
}
head(dc_data)
dim(dc_data)
title
title
str_trim(str_extract(b2, ("(?<=</strong>).*(?=</a>)")))
url <- "https://finance.naver.com/item/sise_day.naver?code=036570&page=1""
install.packages("htmltab")
install.packages("htmltab")
library(htmltab)
url <- "https://finance.naver.com/item/sise_day.naver?code=036570&page=1"
b <- htmltab(url, encoding = "UTF-8")
b
url <- "https://finance.naver.com/item/sise_day.naver?code=036570&page=1"
b <- htmltab(url, encoding = "UTF-8")
url <- "view-source:https://finance.naver.com/item/sise_day.naver?code=036570&page=1"
rb <- htmltab(url, encoding = "UTF-8")
b <- htmltab(url, encoding = "UTF-8")
b
url <- "https://finance.naver.com/item/sise_day.naver?code=036570&page=1"
b <- htmltab(url, encoding = "UTF-8")
b
(htmltab)
#install.packages("htmltab")
library(htmltab)
url <- "https://finance.naver.com/item/sise_day.naver?code=036570&page=1"
b <- htmltab(url, encoding = "UTF-8")
b
b <- htmltab(url, encoding = "UTF-8")
b
#install.packages("htmltab")
library(htmltab)
url <- "https://finance.naver.com/item/sise_day.naver?code=036570&page=1"
b <- htmltab(url, encoding = "UTF-8")
htmltab(url, encoding = "UTF-8")
htmltab(url, encoding = "UTF-8")
b
url <- "https://finance.naver.com/item/sise.naver?code=036570"
htmltab(url, encoding = "UTF-8")
b
url <- "https://finance.naver.com/item/sise_day.naver?code=036570&page=2"
htmltab(url, encoding = "UTF-8")
b
https://finance.naver.com/item/sise_day.naver?code=036570&page=1
https://finance.naver.com/item/sise_day.naver?code=036570&page=1
https://finance.naver.com/item/sise_day.naver?code=036570&page=1
url <- "https://finance.naver.com/item/sise_day.naver?code=036570&page=1"
htmltab(url, encoding = "UTF-8")
b
library(stringr)
dc_data <- NULL
for(i in 1:10){
url <- paste0("https://gall.dcinside.com/board/lists/?id=superidea&page=", i)
Sys.sleep(runif(1)*2)
b <- readLines(url, encoding = "UTF-8")
#제목/url
index <- which(str_detect(b, "gall_tit ub-word"))[-1]
b2 <- b[index+1]
title <- str_trim(str_extract(b2, ("(?<=</strong>).*(?=</a>)")))
con_url <- str_sub(str_extract(b2, ("(?<=a href=).*(?=em class)")), 3, end = -17)
con_url2 <- paste0("https://gall.dcinside.com/", con_url)
#조회수
hit_index <- which(str_detect(b, "gall_count"))[-1]
hit <- as.numeric(str_sub(str_extract(b[hit_index], ("(?<=gall_count).*(?=</td>)")), 3))
hit
#추천수
rec_index <- which(str_detect(b, "gall_recommend"))[-1]
rec <- as.numeric(str_extract(b[rec_index], ("(?<=gall_recommend\">).*(?=</td>)")))
data <- cbind(title, con_url2, hit, rec) #->one matrix
dc_data <- rbind(dc_data, data)
cat("\n", i)
}
head(dc_data)
dim(dc_data)
setwd("/Users/adrua/Desktop/R-Crawling_new/R-Crawling/")
write.csv(dc_data, "dc_data.csv", row.names = F)
data <- read.csv("dc_data.csv")
head(data)
dim(data)
url <- as.character(data$con_url2);url
i <- 1
contents <- c()
for(i in 1:length(url)){
b <- readLines(url[i], encoding = "UTF-8")
Sys.sleep(runif(1)*2)
b2 <- b[which(str_detect(b, "gallview_contents")):which(str_detect(b, " 본문 우측 광고 "))]
b3 <- paste(b2, collapse = " ");b3
b4 <- gsub("<.*?>", "", b3);b4
b5 <- gsub("\t|&nbsp;", "", b4) ; b5
con <- str_trim(b5);con
contents <- c(contents, con)
cat("\n", i)
}
dim(data)
data2 <- cbind(data, contents)
write.csv(data2, "dc.csv", row.names = F)
for(i in 1:length(url)){
b <- readLines(url[i], encoding = "UTF-8")
#Sys.sleep(runif(1)*2)
b2 <- b[which(str_detect(b, "gallview_contents")):which(str_detect(b, " 본문 우측 광고 "))]
b3 <- paste(b2, collapse = " ");b3
b4 <- gsub("<.*?>", "", b3);b4
b5 <- gsub("\t|&nbsp;", "", b4) ; b5
con <- str_trim(b5);con
contents <- c(contents, con)
cat("\n", i)
}
length(ur)
length(url)
i <- 1
length(url)
i <- 1
contents <- c()
for(i in 1:length(url)){
b <- readLines(url[i], encoding = "UTF-8")
#Sys.sleep(runif(1)*2)
b2 <- b[which(str_detect(b, "gallview_contents")):which(str_detect(b, " 본문 우측 광고 "))]
b3 <- paste(b2, collapse = " ");b3
b4 <- gsub("<.*?>", "", b3);b4
b5 <- gsub("\t|&nbsp;", "", b4) ; b5
con <- str_trim(b5);con
contents <- c(contents, con)
cat("\n", i)
}
dim(data)
dim(data)
data2 <- cbind(data, contents)
write.csv(data2, "dc.csv", row.names = F)
data2
data2
data
contents
dim(data)
data2 <- cbind(data, contents)
data2
dim(data)
head(data2)
contents
head(contents)
con <- str_trim(b5);con
con
head(data)
data2 <- cbind(data, contents)
head(data2)
dim(data)
head(contents)
head(data2)
write.csv(data2, "dc.csv", row.names = F)
head(data)
dim(contents)
contents
data2 <- cbind(data, contents)#에러
write.csv(data2, "dc.csv", row.names = F)
head(contents)
dim(contents)
write.csv(data2, "dc.csv", row.names = F) ##이거 아닌 것 같은데.
write.csv(data2, "dc.csv", row.names = F) ##이거 아닌 것 같은데.
